
import streamlit as st
from models.gpt import call_gpt
import json
import os

st.set_page_config(page_title="GPT ä¸­æ–‡å†™ä½œåŠ©æ‰‹", layout="wide")
st.title("âœï¸ GPT ä¸­æ–‡å†™ä½œåŠ©æ‰‹")

st.markdown("è¾“å…¥æçº²åï¼Œå°†è°ƒç”¨ OpenAI çš„ GPT æ¨¡å‹ç”Ÿæˆå†™ä½œå†…å®¹ã€‚")

# åˆå§‹åŒ– session çŠ¶æ€
if "topic" not in st.session_state:
    st.session_state.topic = ""
if "custom_prefix" not in st.session_state:
    st.session_state.custom_prefix = ""
if "prompt_template" not in st.session_state:
    st.session_state.prompt_template = "é€šç”¨"

template_prefix = {
    "é€šç”¨": "è¯·æ ¹æ®ä»¥ä¸‹æçº²ç”Ÿæˆä¸€æ®µè¿è´¯çš„ä¸­æ–‡å†…å®¹ï¼š",
    "å­¦æœ¯è®ºæ–‡": "è¯·æ ¹æ®ä»¥ä¸‹æçº²ï¼Œç”Ÿæˆä¸€æ®µç¬¦åˆå­¦æœ¯è®ºæ–‡é£æ ¼çš„æ–‡å­—ï¼š",
    "å·¥ä½œæ±‡æŠ¥": "è¯·æ ¹æ®ä»¥ä¸‹æçº²ï¼Œç”Ÿæˆä¸€ä»½ç»“æ„æ¸…æ™°çš„å·¥ä½œæ±‡æŠ¥å†…å®¹ï¼š",
    "å¿ƒå¾—æ€»ç»“": "è¯·æ ¹æ®ä»¥ä¸‹æçº²ï¼Œç”Ÿæˆä¸€æ®µä¸ªäººå¿ƒå¾—æ€»ç»“ç±»å‹çš„å†…å®¹ï¼š"
}

st.session_state.prompt_template = st.selectbox("ğŸ“‹ å†™ä½œæ¨¡æ¿", list(template_prefix.keys()), index=list(template_prefix.keys()).index(st.session_state.prompt_template))
st.session_state.custom_prefix = st.text_area("âœï¸ è‡ªå®šä¹‰æç¤ºè¯å‰ç¼€ï¼ˆå¯é€‰ï¼‰", value=st.session_state.custom_prefix)
st.session_state.topic = st.text_area("ğŸ“ è¾“å…¥å†™ä½œæçº²", height=200, value=st.session_state.topic)

gpt_model = st.radio("âš™ï¸ GPT æ¨¡å‹ç‰ˆæœ¬", ["gpt-3.5-turbo", "gpt-4o"], horizontal=True)

# å†å²è®°å½•
history_file = "history.json"
history = []
if os.path.exists(history_file):
    with open(history_file, "r", encoding="utf-8") as f:
        history = json.load(f)

st.markdown("---")
st.subheader("ğŸ“œ å†å²è®°å½•")
if history:
    for i, record in enumerate(reversed(history[-5:])):
        with st.expander(f"ğŸ“„ ç¬¬ {len(history) - i} æ¡è®°å½•ï¼ˆæ¨¡æ¿ï¼š{record['template']}ï¼‰"):
            st.code(record['prompt'], language="markdown")
            st.markdown(record['results'].get("content", "ï¼ˆæ— å†…å®¹ï¼‰"))
else:
    st.info("æš‚æ— å†å²è®°å½•ã€‚")

# ç”ŸæˆæŒ‰é’®
if st.button("ğŸš€ å¼€å§‹ç”Ÿæˆ") and st.session_state.topic.strip():
    st.info("æ­£åœ¨è°ƒç”¨ GPT ç”Ÿæˆå†…å®¹...")
    prefix = st.session_state.custom_prefix.strip() or template_prefix[st.session_state.prompt_template]
    full_prompt = f"{prefix}\n{st.session_state.topic}"
    content, usage = call_gpt(full_prompt, model=gpt_model, return_usage=True)

    st.markdown("### ğŸ“Œ GPT ç”Ÿæˆå†…å®¹")
    st.write(content)
    st.markdown(f"ğŸ”¢ Token ä½¿ç”¨é‡ï¼š**{usage}**")

    # å­˜å†å²
    history.append({
        "prompt": full_prompt,
        "template": st.session_state.prompt_template,
        "results": {"content": content}
    })
    with open(history_file, "w", encoding="utf-8") as f:
        json.dump(history, f, ensure_ascii=False, indent=2)
    st.success("âœ… å†™ä½œå®Œæˆï¼Œå†å²è®°å½•å·²ä¿å­˜ã€‚")
else:
    st.caption("è¯·è¾“å…¥æçº²å¹¶ç‚¹å‡»ç”Ÿæˆ")

